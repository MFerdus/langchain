{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from constants import openai_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a acting financial advisor for people.\\nIn an easy way, explain the basics of income tax.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "demo_template='''I want you to act as a acting financial advisor for people.\n",
    "In an easy way, explain the basics of {financial_concept}.'''\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['financial_concept'],\n",
    "    template=demo_template\n",
    "    )\n",
    "\n",
    "prompt.format(financial_concept='income tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19752\\3744349149.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm=OpenAI(temperature=0.7)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19752\\3744349149.py:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain1=LLMChain(llm=llm,prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import OpenAI\n",
    "# (pip install -U langchain-community)\n",
    "\n",
    "llm=OpenAI(temperature=0.7)\n",
    "chain1=LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19752\\2565712623.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain1.run('GDP')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nGDP, or Gross Domestic Product, is a measure of a country's economic output or total economic activity. It is often used as an indicator of a country's overall economic health. GDP is calculated by adding up the total value of all goods and services produced within a country's borders in a given period of time, usually a year.\\n\\nTo understand GDP, think of it as a big pie. The size of the pie represents the total economic output of a country. This includes everything that is produced within the country, whether it's goods like cars and food, or services like haircuts and banking.\\n\\nNow, let's say the pie grows bigger. This means that the country's GDP has increased. This can happen when more goods and services are being produced, or when there is an increase in the prices of goods and services. On the other hand, if the pie gets smaller, it means that the country's GDP has decreased.\\n\\nGDP is important because it gives us an idea of how well a country's economy is doing. A higher GDP usually means that the country is producing more goods and services, which can lead to more jobs and higher wages for its citizens. However, it's important to note that GDP is not the only measure of a country's economic\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.run('GDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In an easy way translate the following sentence 'How are you' into hindi\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Language Translation\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template='''In an easy way translate the following sentence '{sentence}' into {target_language}'''\n",
    "language_prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\",'target_language'],\n",
    "    template=template,\n",
    ")\n",
    "language_prompt.format(sentence=\"How are you\",target_language='hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19752\\1957911611.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain2({'sentence':\"Hello How are you\",'target_language':'bangla'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello How are you',\n",
       " 'target_language': 'bangla',\n",
       " 'text': '\\n\\n\"নমস্কার আপনি কেমন আছেন?\" (Namaskar apani kemon achen?)'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=LLMChain(llm=llm,prompt=language_prompt)\n",
    "\n",
    "chain2({'sentence':\"Hello How are you\",'target_language':'bangla'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create the `FewShotPromptTemplate` object.\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\\n\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input='big'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small\\n\\nWord: fast\\nAntonym: slow'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
